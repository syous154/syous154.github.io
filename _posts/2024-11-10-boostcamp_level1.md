# CV 기초 프로젝트 Wrap UP Report

---

## 1. 프로젝트 개요

### 프로젝트 주제

스케치 이미지 분류 경진대회는 주어진 스케치 이미지 데이터를 활용해 이미지가 나타내는 객체를 정확히 분류하는 인공지능 모델을 개발하는 대회입니다. 이 대회는 컴퓨터 비전 분야에서 비정형 데이터 인식 및 분류 문제 해결에 중점을 둡니다. 참가자들은 스케치의 기본 형태와 구조를 학습시켜 모델이 객체를 인식하도록 합니다.

### 프로젝트 구현 내용

- 데이터 전처리 : 주어진 스케치 이미지의 특성을 고려하여 전처리하고 ‘cv 기초 프로젝트’에서 배웠던 기술들로 이미지를 증강시켜, 모델 학습을 위한 최적의 형태로 구성
- 모델 개발 : ‘cv 기초 프로젝트’에서 배웠던 여러 기술들을 사용해 스케치 이미지를 분석하고 분류하는 딥러닝 모델을 개발
- 학습 및 평가 : 학습 데이터를 사용해 모델을 훈련시키고, 검증 데이터로 모델의 성능을 검증

### 활용 장비 및 재료

개발 환경 : AI Stages 제공 서버(V100 GPU 4개)

개인 컴퓨터 (VSCode)

협업 툴 : Notion, Slack, Github, Zoom

### 프로젝트 코드 구조 및 사용 데이터셋의 구조도

**데이터 셋 구조**

- 전체 이미지 개수: 25,035장
- 클래스 수: 500개, class별 29~31개의 이미지
- ImageNet-Sketch 데이터셋을 사용

![스크린샷 2024-09-30 오전 5.41.31.png](%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-09-30_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_5.41.31.png)

**코드 구조**

![스크린샷 2024-09-30 오전 10.30.51.png](%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-09-30_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.30.51.png)

---

## 2. 프로젝트 팀 구성 및 역할

| 은의찬 | - 모델 서칭 및 구조
- 하이퍼 파라미터 개선
- tta, pseudo labling |
| --- | --- |
| 안주형 | - 파이썬 모듈화 진행
- confusion matrix 구성 |
| 김기수 | - 파이썬 모듈화 진행
- 모델 서칭 및 구조
- 하이퍼 파라미터 개선 |
| 문채원 | - 모델 서칭 및 구조
- 하이퍼 파라미터 개선
- 다양한 성능 개선 기법 시도 |
| 장지우 | - 모델 서칭 및 구조
- 데이터 EDA 진행
- 다양한 성능 개선 기법 시도 |
| 이재훈 | - 모델 서칭 및 구조
- 모델 앙상블 진행
- Text-to-Image 데이터 증강 |

---

## 3. 프로젝트 수행 절차 및 방법

### 3-1. 프로젝트 협업 방식

 첫 프로젝트는 역할을 나누어서 진행하는 것보다 모든 프로세스에 대해서 다 같이 하는 방향으로

프로젝트를 진행하기로 결정했다.

- 협업 방식
    - 노션 페이지를 이용해 서버 사용 현황을 표시하고 해야할 일과 실험을 기록한다.
    - github를 이용해 코드의 변경점을 관리한다.

### 3-2. 프로젝트 수행 과정

 1. EDA - 주어진 데이터에 대해서 탐색적 데이터 분석을 진행하였다.

1. Preprocessing
2. Augmentation - 어떤 증강 기법을 사용할 지 실험하였다.
3. Model Research - 기존 모델이나 모델에 층을 쌓아 실험하였다.
4. Parameter Experiments - Optimizer, Scheduler, Parameter
5. 최적화 - Pseudo labeling, label smoothing, Error-Driven Learning, Progressive resizing
6. 시각화 - Confusion matrix, error-class visualization
7. 앙상블 - Soft voting, Hard voting, Ensemble of Ensembles, stacking, snapshot

---

## 4. 프로젝트 수행 결과

- EDA
    - 학습 데이터셋
        - 총 15,021개 이미지
            - 정보 : (Class_name, image_path, target)
            - 주로 손으로 그린 드로잉이나 스케치
            - 객체, 동물, 풍경 등 다양한 카테고리
            - 400 ~ 800 pixel 사이의 평균 높이와 너비
            - 200 ~ 250 사이 RGB 값의 분포로 전반적으로 이미지의 밝기와 채도가 높은편
            - Outlier - 종횡비가 매우 크거나, 작은 이미지가 존재
        - 500개 클래스
        - 각 클래스 당 29~31개 이미지
    - 테스트 데이터 셋
        - 10014개 이미지
            - 정보 : image_path
    - 평가 지표 : Accuracy

- Transform
    
    
    | 사용한 조합 | val_accuracy | val_loss |
    | --- | --- | --- |
    | baseline | 0.6812 | 1.3400 |
    | 1. 종횡비(Pad, Normalize) + CLAHE / colorjitter, Flip, 밝기 조절, Grayscale(0.5) | 0.5780 | 1.7819 |
    | 2. 종횡비 + CLAHE / colorjitter, Flip, 밝기 조절, Grayscale(1.0) | 0.5903 | 1.7303 |
    | 3. 종횡비 | 0.6899 | 1.3150 |
    | 4. 종횡비 / CLAHE , H_Flip, Rotate, RandBrightContrast | 0.6869 | 1.2781 |
    | 5. CLAHE / | 0.6799 | 1.3396 |
    | 6. 종횡비 / CLAHE , H_Flip, Rotate, RandBrightContrast | 0.6666 | 1.4110 |
    | 7. 종횡비 / H_Flip, Rotate, RandBrightContrast, 그레이스케일(1.0) | 0.6855 | 1.3493 |
    | 8. 종횡비 / Colorjitter, H_Flip, Rotate, RandBrightContrast | 0.6795 | 1.3475 |
    | 9. Resize, Normalize / 종횡비, H_Flip, Rotate, RandBrightContrast | 0.6519 | 1.4446 |
    | 10. 종횡비 / Rotate, RandBrightContrast | 0.6652 | 1.4176 |
    | 11. 종횡비 / H_Flip, Rotate, 그레이스케일(0.5) | 0.6832 | 1.3146 |
    | 12. 종횡비 / H_Flip, Rotate, RandBrightContrast, 그레이스케일(1.0) | 0.6832 | 1.2942 |
    | 13. 종횡비 / H_Flip, Rotate, RandBrightContrast, 그레이스케일(1.0), CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=1.0) | 0.6875 | 1.3088 |
    - 결론
        - 3번은 훈련 손실, 검증 손실 꾸준히 감소, 검증 정확도 안정적 증가
        - 4번은 검증 손실, 정확도 3번과 비슷, 성능이 안정적
        - 14번은 검증 손실이 감소, 검증 정확도 향상, 근데 후반부로 갈수록 성능 수렴하는 모습
        
         ⇒ 3, 14 채택
        
- Augmentation
    
    
    | 모델 | train_acc | train_loss | val_acc | val_loss |
    | --- | --- | --- | --- | --- |
    | 1. Baseline | 0.8472 | 0.7993 | 0.6982 | 1.2475 |
    | 2. ShiftScale + 가우시안노이즈 + 탄성 변형 + 격자 왜곡 + 원근 변환 + 선명도 + 블러 | 0.6537 | 1.5651 | 0.5960 | 1.6580 |
    | 3. ShiftScale + 가우시안노이즈 + 탄성 변형 + 격자 왜곡 + 원근 변환 + 선명도 + 블러 + 흑백 반전 |  |  |  |  |
    | 4. 가우시안 노이즈 | 0.8500 | 0.7764 | 0.6865 | 1.3135 |
    | 5. Elastic Transform | 0.7744 | 1.0780 | 0.6616 | 1.3923 |
    | 6. GridDistortion | 0.8186 | 0.9138 | 0.6709 | 1.3604 |
    | 7. Perspective | 0.8220 | 0.8848 | 0.6755 | 1.3234 |
    | 8. OneOf sharp, blur | 0.8290 | 0.8736 | 0.6762 | 1.3624 |
    | 9. inverting | 0.8287 | 0.8798 | 0.6822 | 1.3838 |
- 모델 개선 과정
    1. 먼저 여러 모델들을 비교하며 우수한 성능을 보이는 모델을 선정하여, 각 파라미터 값 변경과 실험을 통해 다음과 같이 적합한 모델을 탐색하였고, 스케쥴러, 옵티마이저, 증강 실험을 통해 최적의 성능을 확보했다.
        - CNN 계열
            1. Resnet101 + 전처리 + Progressive Resizing : Validation Acc: 0.8130
            2. EfficientV2  |   Validation Acc : 0.8210
        - ViT 계열
            1. deit_base_patch16_224 : Validation Acc: 0.8406
            2. swin_s3_base_224 : 0.8780
            3. vit_base_patch16_224 : Validation Acc : 0.8313
        - 하이브리드 계열
            1. coatnet_2_rw_224(label_smoothing=0.1) 0.8840
            2. 각 클래스당 50장씩 이미지 추가 + coatnet_2_rw_224 : 0.8860
            3. convnext_base : 0.8850
            
    2. 이후, Confusion Matrix를 plot하여 오분류된 클래스를 확인하였고, 특정 클래스에 대해 데이터를 증강하여 학습을 진행했다. 
    
    1. 모델 성능이 어느 정도 수렴하여, 앙상블을 통한 성능 향상을 목표로 했다. 앙상블 기법은 평균법, 가중 평균법, 스태킹, 보팅, 스냅샷, K-Fold 를 시도했으며, 각 기법 별 최고 성능을 보인 보팅을 모델을 변경해가며 실행하여 결과를 도출했다.

- Output
    - 최종 성능과 순위는 다음과 같다
        
        ![image.png](image.png)
        

---

## 5. 자체 평가 의견

### 5.1 잘한 점

- 성능 향상을 위해 여러가지 가설을 세우며 실험을 진행한 결과 지속적으로 성능을 올리는 결과를 얻을 수 있었다.
- 앙상블 기법을 딥러닝 모델에 사용하면서 성능을 높일 수 있음을 직접 확인할 수 있었다.
- 여러 데이터 증강 기법을 사용하면서 특정 데이터 셋에 알맞는 증강기법을 선택하는 방법을 알 수 있었다.
- 멘토링, 오피스 아워 등에서 얻은 방법들을 적극적으로 적용해 보았다.

### 5.2 아쉬운 점

- 시간적인 문제로 좀 더 다양한 모델과 다양한 앙상블 기법을 실험해 보지 못해 아쉬웠다.
- Git이나 MLFlow, WandB 등 팀프로젝트 진행 시 많은 도움이 되는 툴을 사용하지 않아 협업이 잘 되지 않은 것 같아 아쉬웠다.
- 역할 분담 및 계획 수립을 확실히 하지 않은 것이 아쉬웠다.
- 대회 초반의 제출 기회를 많이 활용하지 못해 마지막에 제출 기회 부족에 힘들어 한 것이 아쉬웠다.
- 실험할 모델 선택 시 실험 가정, 가설을 명확히 세우지 않고 무작정 시도해 본 것이 아쉬웠다.

### 5.3 배운 점

- 기존에 알고 있던 데이터 증강 기법 외에 더 다양한 방법을 알게 되었다.
- 앙상블 기법이 성능 향상에 많은 도움이 되는 것을 직접 느끼는 기회가 되었다.
- 여러 실험을 진행하면서 “어떠한 가설을 기반으로 어떤 선택을 하는지”가 중요한 것을 느끼게 되었다.
- 협업을 위해 역할 분담, 계획 수립, 협업 툴, 커뮤니케이션이 중요하다는 것을 알게 되었다.

---

### 목표 (Objectives)

이번 프로젝트의 주요 목표는 다양한 딥러닝 모델과 기법을 적용하여 이미지 분류 모델의 성능을 향상시키는 것이었습니다. 이를 위해 여러 모델 아키텍처를 탐색하고, 하이퍼파라미터 튜닝, 데이터 증강, 앙상블 기법 등을 시도하여 최적의 성능을 달성하고자 하였습니다.

### 내가 한 것 (What I Did)

1. **다양한 모델 아키텍처 비교 및 실험**
    
    ⇒ 여러 모델을 실험한 결과 CoAtNet 모델이 가장 성능이 좋은 것을 알게됨
    
2. **앙상블 기법 활용**
    
    ⇒ 부스팅 기법을 이용해 EfficientNet V2와 CoAtNet을 앙상블하여 성능을 90%대로 상승함
    
    ⇒ Hard Voting을 통해 최대 91% 성능을 기록함
    
3. **Text-to-Image 데이터 증강**
    
    ⇒ sdxl이라는 Text-to-Image모덿을 이용해 데이터를 더 만들어 학습하는 방법을 시도
    
4. **잘못 분류된 클래스에 대한 임계값 조절**
    
    ⇒ 잘 틀리는 클래스만 임계값을 조절해 잘 맞출 수 있도록 조정
    

### 한계점 (Limitations)

- 모델 선택시 제대로된 가정을 가지고 진행하지 않고 랜덤하게 모델을 선택해 학습을 지행하면서 좋은 모델 선택 전략이 아니었던 것
- KFold 방법도 많이 적용해 보고자 했지만 시간 부족으로 인해 적용하지 못한 점
- Git을 잘 활요하지 않고 팀플을 진행한 점
- 전체적인 일정을 계획하고 진행하지 않아 시간 부족 문제를 느낀 점

### 다음에 시도해볼 것 (Future Improvements)

- 데이터 증강 시에 AutoAugment나 RandomAugmet도 좋은 성능을 보여주는 것으로 보임. 다음에는 이러한 전략도 추가할 것
- Git을 이용해 브렌치를 나눠가며 제대로된 팀플을 진행할 것
- 전체적인 일정을 계획하고 이를 잘 따르며 계획적으로 프로젝트를 진행할 것
